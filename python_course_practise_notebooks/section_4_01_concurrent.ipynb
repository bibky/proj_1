{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПАРАЛЛЕЛЬНЫЕ ВЫЧИСЛЕНИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При большом количестве вычислений, которые не зависят друг от друга, можно использовать техники распараллеливания вычислений. Если запустить, например, python скрипт, выполняющий последовательно набор операций и посмотреть загрузку ЦП, то вы увидите, что есть некоторый процесс, запущенный ОС для выполнения скрипта, и он потребляет определенное кол-во процессорного времени только на одном логическом ядре. Распараллеленный алгоритм позволяет выполнять действия сразу на заданном количестве потоков, что отобразится в виде загрузки сразу нескольких логических ядер.\n",
    "\n",
    "Параллельные вычисления реализуют 3 техниками:\n",
    "1. в многопроцессорном режиме (создаются независимые процессы с собственной памятью);\n",
    "2. в многопоточеном режиме (вычисления происходят в рамках одного процесса с общей памятью);\n",
    "3. в асинхронном режиме (это псевдопараллелизация т.к. вычисления происходят последовательно, но каждый блок периодически отпускает управление для передачи другому блоку, и это происходит достаточно быстро, чтобы создать иллюзию, что все блоки обрабатываются параллельно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MULTIPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys\n",
      "process\n",
      "reduction\n",
      "context\n",
      "Array\n",
      "AuthenticationError\n",
      "Barrier\n",
      "BoundedSemaphore\n",
      "BufferTooShort\n",
      "Condition\n",
      "Event\n",
      "JoinableQueue\n",
      "Lock\n",
      "Manager\n",
      "Pipe\n",
      "Pool\n",
      "Process\n",
      "ProcessError\n",
      "Queue\n",
      "RLock\n",
      "RawArray\n",
      "RawValue\n",
      "Semaphore\n",
      "SimpleQueue\n",
      "TimeoutError\n",
      "Value\n",
      "active_children\n",
      "allow_connection_pickling\n",
      "cpu_count\n",
      "current_process\n",
      "freeze_support\n",
      "get_all_start_methods\n",
      "get_context\n",
      "get_logger\n",
      "get_start_method\n",
      "log_to_stderr\n",
      "parent_process\n",
      "reducer\n",
      "set_executable\n",
      "set_forkserver_preload\n",
      "set_start_method\n",
      "SUBDEBUG\n",
      "SUBWARNING\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    multiprocessing -- это пакет, который позволяет работать с процессами\n",
    "'''\n",
    "import multiprocessing\n",
    "print('\\n'.join(list(filter(lambda x: not x.startswith('_') and x != 'abc', multiprocessing.__dict__.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здесь упорядоченно\n",
      "Hi! I am a process with PID 111967\n",
      "Hi! I am a process with PID 111976\n",
      "Hi! I am a process with PID 111985\n",
      "Hi! I am a process with PID 111994\n",
      "Hi! I am a process with PID 112003\n",
      "\n",
      "Здесь хаотично\n",
      "Hi! I am a process with PID 112012\n",
      "Hi! I am a process with PID 112015\n",
      "Hi! I am a process with PID Hi! I am a process with PID112026\n",
      " 112033\n",
      "Hi! I am a process with PID 112040\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def function_to_separated_process():\n",
    "    print('Hi! I am a process with PID', pid:=os.getpid())\n",
    "\n",
    "processes: List[Process] = [\n",
    "    Process(target=function_to_separated_process, args=())\n",
    "    for _ in range(5)\n",
    "]\n",
    "print('Здесь упорядоченно')\n",
    "for p in processes:\n",
    "    p.start()   # сначала мы запускам процесс\n",
    "    p.join()    # затем ждем его завершения прежде чем начать следующий\n",
    "\n",
    "print('\\nЗдесь хаотично')\n",
    "\n",
    "processes: List[Process] = [\n",
    "    Process(target=function_to_separated_process, args=())\n",
    "    for _ in range(5)\n",
    "]\n",
    "# run processes\n",
    "_ = list(map(lambda p: p.start(), processes))   # сначала запускаем все процессы (так что выполняться они начинают параллельно)\n",
    "# wait till the end, the order is chaotic\n",
    "_ = list(map(lambda p: p.join(), processes))    # и ждем когда они завершатся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    В зависимости от платформы, multiprocessing поддерживает 3 способа создания процесса:\n",
    "    1. \"spawn\" -- родительский процесс создает новый процесс с интерпретатором python. \n",
    "        Дочерний процесс наследует только необходимые ресурсы, так что эта процедура\n",
    "        более щадаще расходует ресурсы системы, но требует больше времени для своей инициализации.\n",
    "        Это дефолтный метод в Windows, macOS\n",
    "    2. \"fork\" -- родительский процесс вызывает os.fork() в интерпретаторе. \n",
    "        Созданный дочерний процесс копия родительского, и используются все аналогичные ресурсы.\n",
    "        Этот метод быстрее, но более дорогостоящий по ресурсам, чем spawn. \n",
    "        Дефолтный в POSIX (UNIX) системах\n",
    "    3. \"forkserver\" -- спавнится процесс-сервер. Каждый раз, когда нужен новый процесс,\n",
    "        запрос отправляется процессу-серверу, чтобы он создал новый процесс.\n",
    "\n",
    "    Для выбора метода нужно вызвать multiprocessing.set_start_method(*method*).\n",
    "    Этот метод вызывается в начале программы, до того, как что-то будет распараллелено\n",
    "    (то есть до создания новых процессов)\n",
    "\n",
    "    Вероятно, код ниже выдаст ошибку в интерпретаторе. Рекомендуется запускать .py скрипт\n",
    "'''\n",
    "# Process\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "\n",
    "def function_to_separated_process():\n",
    "    print('Hi! I am a process with PID', pid:=os.getpid())\n",
    "\n",
    "# давайте спавнить\n",
    "multiprocessing.set_start_method('spawn')   # вызывается единожды в программе до начала всего!\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    processes: List[Process] = [\n",
    "        Process(target=function_to_separated_process, args=())\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "    print('Здесь упорядоченно')\n",
    "    for p in processes:\n",
    "        p.start()   # сначала мы запускам процесс\n",
    "        p.join()    # затем ждем его завершения прежде чем начать следующий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am a process with PID 132569\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Альтернативно можно не устанавливать метод создания процессов,\n",
    "    а вытягивать контекст с помощью метода get-context\n",
    "'''\n",
    "\n",
    "# Process\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "\n",
    "def function_to_separated_process():\n",
    "    print('Hi! I am a process with PID', pid:=os.getpid())\n",
    "\n",
    "_context: multiprocessing.context = multiprocessing.get_context('fork') # spawn \n",
    "if __name__ == '__main__':\n",
    "    p = _context.Process(target=function_to_separated_process, args=())\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process ID\n",
      "29004\n",
      "29006\n",
      "29008\n",
      "29010\n",
      "29012\n",
      "\n",
      "Pipe\n",
      "msg from pipe: 1000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Обмен данными между процессами (вам действительно это нужно?)\n",
    "    Обмен данными между процессами осуществияется с помощью очередей Queue и\n",
    "    каналов Pipe.\n",
    "'''\n",
    "# Process\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue, Pipe\n",
    "\n",
    "print('Queue')\n",
    "\n",
    "def use_queue_to_send_pid(q: Queue):\n",
    "    q.put(os.getpid())\n",
    "    return None\n",
    "\n",
    "q = Queue()\n",
    "processes: List[Process] = [\n",
    "    Process(target=use_queue_to_send_pid, args=(q,))\n",
    "    for _ in range(5)\n",
    "]\n",
    "\n",
    "# run processes\n",
    "_ = list(map(lambda p: p.start(), processes))   # сначала запускаем все процессы (так что выполняться они начинают параллельно)\n",
    "# wait till the end, the order is chaotic\n",
    "_ = list(map(lambda p: p.join(), processes))    # и ждем когда они завершатся\n",
    "\n",
    "print('Process ID')\n",
    "for p in processes:\n",
    "    print(msg:=q.get())\n",
    "\n",
    "print('\\nPipe')\n",
    "\n",
    "def use_pipe_to_send_pid(pipe):\n",
    "    pipe.send(os.getgid())\n",
    "    pipe.close()\n",
    "    return None\n",
    "\n",
    "main_pipe, child_pipe = Pipe()\n",
    "p = Process(target=use_pipe_to_send_pid, args=(child_pipe, ))\n",
    "p.start()\n",
    "print('msg from pipe:', main_pipe.recv())\n",
    "p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здесь упорядоченно\n",
      "Hi! I am a process with PID 29114\n",
      "Hi! I am a process with PID 29123\n",
      "Hi! I am a process with PID 29132\n",
      "Hi! I am a process with PID 29141\n",
      "Hi! I am a process with PID 29150\n",
      "\n",
      "Здесь хаотично (нет, не хаотично, процесс блокирует остальные и выполняет свой блок кода)\n",
      "Hi! I am a process with PID 29159\n",
      "Hi! I am a process with PID 29167\n",
      "Hi! I am a process with PID 29162\n",
      "Hi! I am a process with PID 29172\n",
      "Hi! I am a process with PID 29177\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Есть механика блокировки управления, реализуемая через Lock\n",
    "'''\n",
    "\n",
    "from multiprocessing import Lock\n",
    "\n",
    "def function_to_separated_process(lock: Lock):\n",
    "    lock.acquire()\n",
    "    print('Hi! I am a process with PID', pid:=os.getpid())\n",
    "    lock.release()\n",
    "\n",
    "lock = Lock()\n",
    "processes: List[Process] = [\n",
    "    Process(target=function_to_separated_process, args=(lock,))\n",
    "    for _ in range(5)\n",
    "]\n",
    "print('Здесь упорядоченно')\n",
    "for p in processes:\n",
    "    p.start()   # сначала мы запускам процесс\n",
    "    p.join()    # затем ждем его завершения прежде чем начать следующий\n",
    "\n",
    "print('\\nЗдесь хаотично (нет, не хаотично, процесс блокирует остальные и выполняет свой блок кода)')\n",
    "\n",
    "lock = Lock()\n",
    "processes: List[Process] = [\n",
    "    Process(target=function_to_separated_process, args=(lock,))\n",
    "    for _ in range(5)\n",
    "]\n",
    "# run processes\n",
    "_ = list(map(lambda p: p.start(), processes))   # сначала запускаем все процессы (так что выполняться они начинают параллельно)\n",
    "# wait till the end, the order is chaotic\n",
    "_ = list(map(lambda p: p.join(), processes))    # и ждем когда они завершатся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 176666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process process176669 \n",
      "176678process\n",
      " 176683process\n",
      " 176694\n",
      "process 176703process\n",
      " 176714process\n",
      " 176721process\n",
      " 176730process\n",
      " 176739\n",
      "\n",
      "Array [176666.0, 176669.0, 176678.0, 176683.0, 176694.0, 176703.0, 176714.0, 176721.0, 176730.0, 176739.0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Shared Memory -- это память, разделяемая между процессами. \n",
    "        Если большой объем данных используется во всех (многих) процессах без изменения содержимого,\n",
    "        имеет смысл поместить блок данных в общую память.\n",
    "'''\n",
    "from multiprocessing import Value, Array\n",
    "\n",
    "def put_pid(shared_array: Array, i: int) -> None:\n",
    "    pid = os.getpid()\n",
    "    shared_array[i] = pid\n",
    "    print('process', pid)\n",
    "    return None\n",
    "\n",
    "n_processes: int = 10\n",
    "shared_array: Array = Array(typecode_or_type='d', size_or_initializer=n_processes)\n",
    "processes = [Process(target=put_pid, args=(shared_array, i)) for i in range(n_processes)]\n",
    "\n",
    "# run processes\n",
    "_ = list(map(lambda p: p.start(), processes))   # сначала запускаем все процессы (так что выполняться они начинают параллельно)\n",
    "# wait till the end, the order is chaotic\n",
    "_ = list(map(lambda p: p.join(), processes))    # и ждем когда они завершатся\n",
    "\n",
    "print('\\nArray', list(shared_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID\n",
      "Hi! I am a process with PID \n",
      "Hi! I am a process with PID       202749  202754202751202757202750202752202748\n",
      "202755202756202753\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Часто вместо процессов удобно использовать пул процессов (Pool)\n",
    "'''\n",
    "\n",
    "from multiprocessing import Pool, Lock\n",
    "from typing import Any\n",
    "\n",
    "def function_to_separated_process(_):\n",
    "    print('\\nHi! I am a process with PID', pid:=os.getpid())\n",
    "\n",
    "# используя контекстный менеджер, создаем пул, передавая количество процессов\n",
    "with Pool(processes=10) as pool:\n",
    "    res: List[Any] = pool.map(function_to_separated_process, range(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASKS:\n",
    "'''\n",
    "    Имплементируйте в многопроцессорном режиме генерацию траекторий для разных\n",
    "    стохастических процессов.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MULTITHREADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Далее изучим многопоточные операции. Основные проблемы, возникающая с многопоточностью:\\n        race condition и deadlock\\n    1е - состояние гонки, когда 2 потока претендуют за один ресурс (ячейку памяти),\\n        что приводит к\\n    2е - блокировка ресурса (ячейки памяти), когда один поток взял в работу данные, и заблокировал их,\\n        чтобы другие потоки не могли с ними ничего делать. Параллельно этот поток ждет данные от, скажем, другого потока,\\n        который в свою очередь для завершения своих операций требует заблокированный 1м потоком ресурс.\\n        Получается следующее: \\n        1й поток не может завершиться, \\n            потому что 2й поток не может передать ему данные,\\n                потому что 1й поток не может завершиться,\\n                    потому что 2й поток не может завершиться ...\\n                        и это называется deadlock.\\n        Ему предшествует состояние гонки, которое абсолютно нежелательно допускать никогда.\\n    К счастью, интерпретатор python оснащен механизмом GIL (Global Interpreter Lock), который\\n        гарантирует, что в каждый момент времени исполняется только 1 поток - потрясающе!,\\n        это почти сводит на нет пользу многопоточного исполнения - потоки все равно будут исполняться последовательно.\\n        Тем не менее, ускорения добиться можно.\\n    В python 3.13, однако, допускается выключить GIL - https://www.infoworld.com/article/3552750/get-started-with-the-free-threaded-build-of-python-3-13.html\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Далее изучим многопоточные операции. Основные проблемы, возникающая с многопоточностью:\n",
    "        race condition и deadlock\n",
    "    1е - состояние гонки, когда 2 потока претендуют за один ресурс (ячейку памяти),\n",
    "        что приводит к\n",
    "    2е - блокировка ресурса (ячейки памяти), когда один поток взял в работу данные, и заблокировал их,\n",
    "        чтобы другие потоки не могли с ними ничего делать. Параллельно этот поток ждет данные от, скажем, другого потока,\n",
    "        который в свою очередь для завершения своих операций требует заблокированный 1м потоком ресурс.\n",
    "        Получается следующее: \n",
    "        1й поток не может завершиться, \n",
    "            потому что 2й поток не может передать ему данные,\n",
    "                потому что 1й поток не может завершиться,\n",
    "                    потому что 2й поток не может завершиться ...\n",
    "                        и это называется deadlock.\n",
    "        Ему предшествует состояние гонки, которое абсолютно нежелательно допускать никогда.\n",
    "    К счастью, интерпретатор python оснащен механизмом GIL (Global Interpreter Lock), который\n",
    "        гарантирует, что в каждый момент времени исполняется только 1 поток - потрясающе!,\n",
    "        это почти сводит на нет пользу многопоточного исполнения - потоки все равно будут исполняться последовательно.\n",
    "        Тем не менее, ускорения добиться можно.\n",
    "    В python 3.13, однако, допускается выключить GIL - https://www.infoworld.com/article/3552750/get-started-with-the-free-threaded-build-of-python-3-13.html\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHON_GIL'] = '0'  # в теории если поставить эту переменную окружения == 0, то GIL отключится\n",
    "                                # если нет, то в интернете написано, как выключить\n",
    "\n",
    "def if_prime(x: int):\n",
    "    if x <= 1:\n",
    "        return 0\n",
    "    elif x <= 3:\n",
    "        return 1\n",
    "    elif x % 2 == 0 or x % 3 == 0:\n",
    "        return 0\n",
    "    i = 5\n",
    "    while i**2 <= x:\n",
    "        if x % i == 0 or x % (i + 2) == 0:\n",
    "            return 0\n",
    "        i += 6\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_performance():\n",
    "    ans: int = 0\n",
    "    for i in range(1_000_000):\n",
    "        ans += if_prime(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858 ms ± 7.21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit check_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# будет работать медленно\n",
    "def check_performance_with_pool():\n",
    "    with ThreadPoolExecutor(max_workers=128) as pool:\n",
    "        ans: List[Any] = pool.map(if_prime, list(range(1_000_000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будет работать медленно\n",
    "def check_performance_with_pool():\n",
    "    with ThreadPoolExecutor(max_workers=12) as pool:\n",
    "        futures: List[concurrent.futures.Future] = [pool.submit(if_prime, i) for i in range(1_000_000)]\n",
    "        ans = sum(future.result() for future in futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    В действительности иногда сложно найти ситуации, где лучше использовать потоки.\n",
    "    Немного более дорогой вариант в плане ресурсов, но более надежный -- использовать процессы.\n",
    "\n",
    "    В заключение представим список библиотек для распараллеливания вычислений в python:\n",
    "        joblib - https://joblib.readthedocs.io/en/stable/\n",
    "        parsl - https://parsl-project.org/\n",
    "        ipyparallel - https://ipyparallel.readthedocs.io/en/latest/     \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASYNCHRONOUS CALCULATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4311/4167421666.py:15: RuntimeWarning: coroutine 'my_coroutine' was never awaited\n",
      "  print(type(my_coroutine()))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/tmp/ipykernel_4311/4167421666.py:16: RuntimeWarning: coroutine 'my_coroutine' was never awaited\n",
      "  print(my_coroutine())        # <coroutine object my_coroutine at 0x7c6eac5efe80>\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'coroutine'>\n",
      "<coroutine object my_coroutine at 0x7c6eac464700>\n",
      "Hello, coroutine\n",
      "\n",
      "\n",
      "Hello, coroutine\n",
      "\n",
      "Awaken\n",
      "Awaken\n",
      "total time = 3.005 \n",
      "\n",
      "Awaken\n",
      "Awaken\n",
      "asynchronously performed time = 2.002\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Начнем с знакомства с корутинами (coroutines) -- подпрограммами, которые можно приостановить для выполнения\n",
    "    других команд с возобновлением их работы с последнего состояния.\n",
    "\n",
    "    AWAITABLES\n",
    "    Объект назывется ожидаемым (awaitable), если к нему можно применить выражение \"await\".\n",
    "    Множество API веб-ресурсов написаны с поддержкой awaitables объектов.\n",
    "    Есть 3 основных объекта : coroutines, Tasks и Futures(не путать с фьючерсами из курса деривативов)\n",
    "    docs: https://docs.python.org/3/library/asyncio.html\n",
    "'''\n",
    "\n",
    "# COROUTINES\n",
    "async def my_coroutine():\n",
    "    print('Hello, coroutine\\n')\n",
    "\n",
    "print(type(my_coroutine()))\n",
    "print(my_coroutine())        # <coroutine object my_coroutine at 0x7c6eac5efe80>\n",
    "await my_coroutine()         # выполнить корутину\n",
    "\n",
    "# TASKS\n",
    "'''\n",
    "    Задачи (Tasks) используются для выполнения блоков кода concurrently (одновременно, параллельно)\n",
    "    Когда задачу оборачивают функциями наподобие asyncio.create_task(), корутина автоматически начинает исполняться в фоне,\n",
    "    без требования ожидания возвращения управления в основной блок кода\n",
    "'''\n",
    "\n",
    "import time\n",
    "import asyncio\n",
    "from asyncio.tasks import Task\n",
    "\n",
    "# для работы в ноутбуках\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print()\n",
    "\n",
    "asyncio.create_task( my_coroutine() )  # начнет выполняться сразу после вызова\n",
    "\n",
    "async def sleep_and_print(time: float) -> None:\n",
    "    await asyncio.sleep(time)\n",
    "    print('Awaken')\n",
    "\n",
    "# запуск корутин consequently (последовательно)\n",
    "start = time.time()\n",
    "for _ in range(1, 3):\n",
    "    sleep_time = _ #random.random()\n",
    "    await sleep_and_print(sleep_time)\n",
    "end = time.time()\n",
    "print('total time =', round(end-start, 3), '\\n') # 3 секунды на выполнение\n",
    "\n",
    "# запуск корутин concurrently (параллельно)\n",
    "start: float = time.time()\n",
    "task_1: Task = asyncio.create_task(sleep_and_print(1))\n",
    "task_2: Task = asyncio.create_task(sleep_and_print(2))\n",
    "await task_1\n",
    "await task_2\n",
    "end: float = time.time()\n",
    "print('asynchronously performed time =', round(end-start, 3)) # уже 2 секунды на выполнение\n",
    "\n",
    "# более современный вариант с использованием TaskGroup и контекстным менеджером\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "    start: float = time.time()\n",
    "    task_1: Task = tg.create_task(\n",
    "        sleep_and_print(1)\n",
    "    )\n",
    "    task_2: Task = tg.create_task(\n",
    "        sleep_and_print(2)\n",
    "    )\n",
    "end: float = time.time()\n",
    "print('with TaskGroup time elapse =', round(end-start, 3)) # те же 2 секунды на выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awaken 1\n"
     ]
    }
   ],
   "source": [
    "# FUTURES\n",
    "'''\n",
    "    Фьючерсы это специальный низко-уровневый ожидаемый объект, который хранит конечный результат корутины.\n",
    "    Когда код ожидает фьючерс ( await future() ), это означает, что корутина в ожидаении пока фьючерс будет \n",
    "    выполнен и возвращен в некотором месте кода. Фьючерсы в основном нужны для реализации callback'ов в коде,\n",
    "    написанном в асинхронном стиле. Обычно фьючерсы используются редко.\n",
    "'''\n",
    "\n",
    "# для демонстрации используем дополнительную библиотеку для работы с фьючерсами\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "def to_exec(_: int):\n",
    "    time.sleep( random.random() )\n",
    "    print('Awaken', _)\n",
    "    return _\n",
    "\n",
    "loop = asyncio.get_running_loop()\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    res: List[Any] = await loop.run_in_executor(\n",
    "        executor, to_exec, 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awaken after 0\n",
      "awaken after 1\n",
      "awaken after 2\n",
      "awaken after 3\n",
      "awaken after 4\n",
      "awaken after 5\n",
      "awaken after 6\n",
      "awaken after 7\n",
      "awaken after 8\n",
      "awaken after 9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    СОЗДАНИЕ И ОБРАБОТКА ЗАДАЧ\n",
    "    asyncio.create_task(coro, *, name=None, context=None) - создание задачи\n",
    "    asyncio.get_running_loop() - возвращает объект цикла, в котором хранятся задачи\n",
    "    task.cancel() - отменить задачу\n",
    "'''\n",
    "\n",
    "import asyncio\n",
    "from asyncio.tasks import Task\n",
    "\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "\n",
    "# пусть корутина возвращает значение, нужно получить к нему доступ\n",
    "# создадим словарь и используем его для сбора ответов\n",
    "_global_coro_ans: Dict[str, Any] = dict()\n",
    "\n",
    "async def sleep_and_print(time_: float) -> None:\n",
    "    global _global_coro_ans\n",
    "    await asyncio.sleep(time_)\n",
    "    print('awaken after', time_)\n",
    "    # переведем аргумент в строку, потому что ключ должен быть неизменяемым объектом\n",
    "    _global_coro_ans[str(time_)] = time_\n",
    "    return time_\n",
    "\n",
    "my_loop = asyncio.get_event_loop()\n",
    "for i in range(10):\n",
    "    _ = my_loop.create_task(\n",
    "        sleep_and_print(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatch_queue\n",
      "sleep_and_print\n",
      "run_cell_async\n",
      "sleep_and_print\n",
      "sleep_and_print\n",
      "sleep_and_print\n",
      "sleep_and_print\n",
      "sleep_and_print\n",
      "Кол-во отмененных задач: 6\n"
     ]
    }
   ],
   "source": [
    "from typing import Set\n",
    "\n",
    "await asyncio.sleep(3) # подождем 3 секунды, некоторые задачи успеют выполниться\n",
    "\n",
    "# # проверим какие задачи еще не выполнены и отменим их\n",
    "pending: Set[Task] = asyncio.all_tasks() # all_tasks возвращает множество (set) выполняющихся задач\n",
    "'''\n",
    "    ВАЖНО: asyncio.all_tasks() возвращает список задач, которые в процессе выполнения\n",
    "    И этот список автоматически обновляется, поэтому выполненные задачи в нем не отображаются.\n",
    "'''\n",
    "num_of_canceled_tasks: int = 0\n",
    "for task in pending:\n",
    "    print(task_name := task.get_coro().__name__)  # выключим только целевые задачи (т.е. 'sleep_and_print')\n",
    "    if task_name == 'sleep_and_print':\n",
    "        task.cancel()\n",
    "        num_of_canceled_tasks += 1\n",
    "print('Кол-во отмененных задач:', num_of_canceled_tasks)\n",
    "# ожидаемо мы отменили 6 задач, потому что они ожидали до выполнения больше 3 секунд\n",
    "# которые мы выделили им в качестве форы до отмены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3}\n"
     ]
    }
   ],
   "source": [
    "# проверим наличие ответов корутин в глобальном словаре\n",
    "print(_global_coro_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awaken after 0\n",
      "awaken after 1\n",
      "awaken after 2\n",
      "awaken after 3\n",
      "awaken after 4\n",
      "awaken after 5\n",
      "awaken after 6\n",
      "awaken after 7\n",
      "awaken after 8\n",
      "awaken after 9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Возвращаясь к asyncio.all_tasks()\n",
    "    Чтобы хранить ссылки на задачи, которые были выполнены,\n",
    "    можно создавать множества с ссылками на эти задачи:\n",
    "'''\n",
    "my_loop = asyncio.get_event_loop()\n",
    "tasks: Set[Task] = set()\n",
    "for i in range(10):\n",
    "    task = my_loop.create_task(\n",
    "        sleep_and_print(i)\n",
    "    )\n",
    "    tasks.add(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep_and_print\n",
      "True\n",
      "result of the coro sleep_and_print : 0\n",
      "sleep_and_print\n",
      "True\n",
      "result of the coro sleep_and_print : 3\n",
      "sleep_and_print\n",
      "True\n",
      "result of the coro sleep_and_print : 2\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "False\n",
      "sleep_and_print\n",
      "True\n",
      "result of the coro sleep_and_print : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    User cases? \\n        Допустим, вы работаете над исследовательским проектом в ipynb \\n        и хотите запустить долго выполняющийся алгоритм. \\n        При этом вы не хотите ждать пока он отработает, а продолжить\\n        выполнять другие задачи в рамках ноутбука. Выполняя блок кода\\n        синхронно, вам придется ждать высвобождения им управления.\\n        Альтернативно, если вы обернете его в асинхронную задачу и отправите\\n        выполняться в фоновом отдельном процессе, то сможете и дальше использовать\\n        ресурсы (переменные, память, процессорное время) ноутбука дальше,\\n        таким образом эффективно распараллелив ваш рабочий процесс.\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-79' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=0>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-82' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=3>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-81' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=2>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-80' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=1>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-83' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=4>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-84' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=5>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-85' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=6>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-86' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=7>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-87' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=8>\n",
      "object type <class 'asyncio.tasks.Task'>\n",
      "object itself <Task finished name='Task-88' coro=<sleep_and_print() done, defined at /tmp/ipykernel_6005/1206983598.py:18> result=9>\n"
     ]
    }
   ],
   "source": [
    "# callback функция, ниже объяснено зачем\n",
    "def print_task_argument(_: Any) -> None:\n",
    "    print('object type', type(_))\n",
    "    print('object itself', _)\n",
    "    return None\n",
    "\n",
    "await asyncio.sleep(3)\n",
    "\n",
    "'''\n",
    "    Данный подход позволяет не использовать костыли наподобие глобальных переменных\n",
    "'''\n",
    "for task in tasks:\n",
    "    print(task_name := task.get_coro().__name__)\n",
    "    if task_name == 'sleep_and_print':\n",
    "        print(done:=task.done())\n",
    "        if done:\n",
    "            print('result of the coro', task_name, ':', task.result())\n",
    "\n",
    "        # мы добавляем в задачу callback, который триггерится при завершении задачи\n",
    "        # в данном примере мы просим распечатать аргумент коллбека\n",
    "        # а потом удалить задачу из списка задач\n",
    "        task.add_done_callback(print_task_argument)\n",
    "        task.add_done_callback(tasks.discard)\n",
    "'''\n",
    "    User cases? \n",
    "        Допустим, вы работаете над исследовательским проектом в ipynb \n",
    "        и хотите запустить долго выполняющийся алгоритм. \n",
    "        При этом вы не хотите ждать пока он отработает, а продолжить\n",
    "        выполнять другие задачи в рамках ноутбука. Выполняя блок кода\n",
    "        синхронно, вам придется ждать высвобождения им управления.\n",
    "        Альтернативно, если вы обернете его в асинхронную задачу и отправите\n",
    "        выполняться в фоновом отдельном процессе, то сможете и дальше использовать\n",
    "        ресурсы (переменные, память, процессорное время) ноутбука дальше,\n",
    "        таким образом эффективно распараллелив ваш рабочий процесс.\n",
    "        Как видите, это очень удобный и мощный инструмент!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    При работе с группой связанных (или не связанных) корутин,\n",
    "    используется TaskGroup, который имплементирует реализацию контекстного менеджера,\n",
    "    внутри которого гарантируется, что все задачи \"в ожидании\", т.е. \n",
    "    выход из контекстного менеджера означает, что все задачи в группе завершены (успешно, неуспешно или неактивны)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "from asyncio.tasks import Task\n",
    "from asyncio import TaskGroup\n",
    "\n",
    "import time\n",
    "from typing import Set, Dict, Any\n",
    "\n",
    "async def sleep_and_print(time_: float) -> None:\n",
    "    global _global_coro_ans\n",
    "    await asyncio.sleep(time_)\n",
    "    print('awaken after', time_)\n",
    "    return time_\n",
    "\n",
    "tasks: Set[Task] = set()\n",
    "async with TaskGroup() as tg:\n",
    "    for tnum in range(5):\n",
    "        tasks.add(\n",
    "            tg.create_task(sleep_and_print(tnum))\n",
    "        )\n",
    "print('Все задачи завершены')\n",
    "for t in tasks:\n",
    "    print(t.done(), t.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    В случае, если внутри группы задач возникает ошибка, то менеджер завершает свою работу,\n",
    "    завершив все остальные задачи.\n",
    "    Пример из https://docs.python.org/3/library/asyncio-task.html#coroutine\n",
    "'''\n",
    "\n",
    "class TerminateTaskGroup(Exception):\n",
    "    \"\"\"Exception raised to terminate a task group.\"\"\"\n",
    "\n",
    "async def force_terminate_task_group():\n",
    "    \"\"\"Used to force termination of a task group.\"\"\"\n",
    "    raise TerminateTaskGroup()\n",
    "\n",
    "async def job(task_id, sleep_time):\n",
    "    print(f'Task {task_id}: start')\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print(f'Task {task_id}: done')\n",
    "\n",
    "try:\n",
    "    async with TaskGroup() as group:\n",
    "        # spawn some tasks\n",
    "        group.create_task(job(1, 0.5))\n",
    "        group.create_task(job(2, 1.5))\n",
    "        # sleep for 1 second\n",
    "        await asyncio.sleep(1)\n",
    "        # add an exception-raising task to force the group to terminate\n",
    "        group.create_task(force_terminate_task_group())\n",
    "except* TerminateTaskGroup:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### РАБОТА С API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Асинхронные вычисления часто используются при работе с веб-ресурсами,\\n    поскольку часто приходится просто ждать ответ на запрос с сервера.\\n    Есть много задач, где приходится иметь дело с подключением к API \\n    какого-нибудь интернет ресурса. \\n    Здесь мы будем подключаться к крипто-биржам и\\n    скачивать исторические данные и данные в режиме реального времени\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Асинхронные вычисления часто используются при работе с веб-ресурсами,\n",
    "    поскольку часто приходится просто ждать ответ на запрос с сервера.\n",
    "    Есть много задач, где приходится иметь дело с подключением к API \n",
    "    какого-нибудь интернет ресурса. \n",
    "    Здесь мы будем подключаться к крипто-биржам и\n",
    "    скачивать исторические данные и данные в режиме реального времени\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    DERIBIT API\n",
    "    https://docs.deribit.com/?python\n",
    "    На сайте с документацией приведены примеры запросов на python и описание ответов на эти запросы.\n",
    "    Для работы потребуется установить библиотеку websockets\n",
    "'''\n",
    "\n",
    "import json\n",
    "import websockets\n",
    "\n",
    "import asyncio\n",
    "# для работы в ноутбуках\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "# формируем запрос в виде словаря\n",
    "msg = \\\n",
    "{\n",
    "  \"method\" : \"public/get_instruments\",\n",
    "  \"params\" : {\n",
    "    \"currency\" : \"BTC\",\n",
    "    \"kind\" : \"future\"\n",
    "  },\n",
    "  \"jsonrpc\" : \"2.0\",\n",
    "  \"id\" : 1\n",
    "}\n",
    "\n",
    "# асинхронная функция для отправки запроса по апи\n",
    "async def call_api(msg: str) -> Dict[str, Any]:\n",
    "   # подключаем вебсокет коннект\n",
    "   async with websockets.connect('wss://test.deribit.com/ws/api/v2') as websocket:\n",
    "      # отправляем запрос\n",
    "      await websocket.send(msg)\n",
    "      # ожидаем ответ\n",
    "      response: str = await websocket.recv() \n",
    "      # возвращаем ответ\n",
    "      return json.loads(response)\n",
    "\n",
    "request = json.dumps(msg) # дампит словарь в строку\n",
    "ans: Dict[str, Any] = asyncio.get_event_loop().run_until_complete(call_api(request))\n",
    "\n",
    "# в полученном ответе мы получаем список торгуемых инструментов\n",
    "print(len(ans['result']))\n",
    "\n",
    "instrument = ans['result'][0]['instrument_name']\n",
    "\n",
    "# получим LOB по инструменту\n",
    "msg = \\\n",
    "{\n",
    "  \"jsonrpc\" : \"2.0\",\n",
    "  \"id\" : 8772,\n",
    "  \"method\" : \"public/get_order_book\",\n",
    "  \"params\" : {\n",
    "    \"instrument_name\" : instrument,\n",
    "    \"depth\" : 50\n",
    "  }\n",
    "}\n",
    "request = json.dumps(msg) # дампит словарь в строку\n",
    "ans: Dict[str, Any] = asyncio.get_event_loop().run_until_complete(call_api(request))\n",
    "\n",
    "# парсим полученный снапшот\n",
    "bids = ans['result']['bids']\n",
    "asks = ans['result']['asks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача.\n",
    "\n",
    "Написать скрипт, который в режиме реального времени с шагом в 1 секунду выгружает снапшоты книги лимитных приказов\n",
    "с биржи deribit, а также список последних сделок по следующим инструментам:\n",
    "BTC-PERPETUAL, ETH-PERPETUAL\n",
    "Создайте несколько задач asyncio.task, которые будут:\n",
    "а) обращаться к бирже и выгружать данные\n",
    "б) собирать их в единый форматированный датафрейм\n",
    "в) сохранять данные на диск\n",
    "\n",
    "все операции должны быть реализованы в асинхронном режиме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTC-2MAY25'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
